{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Human Activity Recognition Using WiFi Signals\n",
        "\n",
        "## Overview\n",
        "Human Activity Recognition (HAR) using WiFi signals leverages the unique properties of wireless channel variations to detect different activities.\n",
        "\n",
        "## Data Format\n",
        "- **WiFi signal data** is similar to image data in structure, represented in the shape `(channels, height, width)`, but with a different interpretation:\n",
        "  - `channels` → **channel**\n",
        "  - `height` → **Time Steps**\n",
        "  - `width` → **Antenna Pairs (transmitter-receiver combinations)**\n",
        "- **Labels** represent a predefined set of classes, as is typical in classification tasks."
      ],
      "metadata": {
        "id": "0NnOoFtyHilj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading Data"
      ],
      "metadata": {
        "id": "1GqPqJNJIWNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"alihabibullah/question-2-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnmdeTv2xPQ2",
        "outputId": "e9a85064-5a4d-43d6-f57d-992c64c4ba29"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/alihabibullah/question-2-data/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8hne08gxqjN",
        "outputId": "d082e542-f100-4617-d530-e7b66117a7a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['WiFiSensingDataset.pt']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oEZvoIOGxqWc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DwIkG1iHVPg",
        "outputId": "c335e81d-ecf2-42bc-c980-5e86b02c4f0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-4d2815cbd2c7>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load(f\"{path}/WiFiSensingDataset.pt\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Load the .pt file\n",
        "data = torch.load(f\"{path}/WiFiSensingDataset.pt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Analyze the Dataset ( Stored in `data`)\n",
        "\n",
        "1. **Determine the number of unique labels** in the dataset.  \n",
        "\n",
        "2. **Determine the shape of the input data** (number of samples and features).  \n",
        "\n",
        "3. **Find the maximum value** in the dataset.  \n",
        "\n",
        "4. **Find the minimum value** in the dataset.  "
      ],
      "metadata": {
        "id": "8vkoyStvJBLl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7lPNBr_UK1nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Build and Evaluate a Neural Network\n",
        "\n",
        "1. **Design a Neural Network (Maximum 5 Layers)**  \n",
        "   Build a compact neural network with no more than 5 layers. Clearly specify the type of each layer (e.g., Dense, Conv2D) and any activation functions used.\n",
        "\n",
        "2. **Evaluate Your Model**  \n",
        "   Train your network on the provided dataset and report the evaluation metrics (e.g., accuracy, loss). Discuss the performance of your model and any challenges faced during training.\n"
      ],
      "metadata": {
        "id": "zbbW9TqJJI84"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hci0PeriJIGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAMgZ-FXJIL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5PHWz6VtLLT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good luck in the exam x)\n",
        "\n",
        "Prepared by: Ahmed Y. Radwan\n"
      ],
      "metadata": {
        "id": "6pqoK28DLPB4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5er_pdi8w5cV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}